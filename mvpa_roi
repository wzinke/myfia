#!/usr/bin/env python

# run searchlight analysis.

###########################################################
##   (c) wolf zinke (2012) - part of the MaFIA toolbox   ##
##         > MAcaque Functional Image Analysis <         ##
##            Licensed under the MIT license             ##
###########################################################

#########################################################################
### import python modules
import os
import argparse

#########################################################################
### get command line arguments

parser = argparse.ArgumentParser(description='Run searchlight analysis on a data set.')
parser.add_argument('ds',  help='data set, single 4D file or list of 3D volumes ("flnm1 flnm2 flnm3")')
parser.add_argument('-attr',  required=True, help='attribute file')
parser.add_argument('-roi',   default=None,  help='roi mask file')
parser.add_argument('-nz',    action='store_false', default=True, help='No z-scoring of the data set')
parser.add_argument('-cnd',   help='targets for subset', action='append', default=[])
parser.add_argument('-clf',   default="smlr", help='Classier (knn, svm, nusvm, smlr)')
parser.add_argument('-ts',    default=2, type=int, help='number of runs used as test set')
parser.add_argument('-onm',   default="MVPA_SL",   help='output file name')

cla = parser.parse_args()

#########################################################################
### load modules necessary for mvpa analysis

import numpy as np

from mvpa2.datasets.mri         import map2nifti
from mvpa2.generators.partition import NFoldPartitioner
from mvpa2.measures.base        import CrossValidation
from mvpa2.misc.errorfx         import mean_match_accuracy, mean_mismatch_error
from mvpa2.misc.io              import SampleAttributes
from mvpa2.datasets.mri         import fmri_dataset
from mvpa2.mappers.zscore       import zscore
from mvpa2.mappers.fx           import mean_sample

#########################################################################
### run searchlight analysis

# load two column text file specifying data attributes
attr = SampleAttributes(cla.attr)

# load data set
ds = fmri_dataset(cla.ds.split(), targets=attr.targets, chunks=attr.chunks, mask=cla.roi)

# apply zsoring run-wise
if cla.nz:
    zscore(ds, chunks_attr='chunks')

# take subset of the data
if len(cla.cnd) > 0:
    cds = ds[np.in1d(ds.T,cla.cnd)]
else:
    cds = ds

# specify the classifier
if cla.clf == "knn":
    from mvpa2.clfs.knn  import kNN
    clf  = kNN()
elif cla.clf == "svm":
    from mvpa2.clfs.svm  import LinearCSVMC
    clf  = LinearCSVMC()
elif cla.clf == "nusvm":
    from mvpa2.clfs.svm  import LinearNuSVMC
    clf  = LinearNuSVMC()
elif cla.clf == "smlr":
    from mvpa2.clfs.smlr import SMLR
    clf  = SMLR()

# method to splitt data into training and test sets
splt = NFoldPartitioner(cvtype=cla.ts, attr='chunks')

#cv = CrossValidation(clf, splt, errorfx=mean_match_accuracy,enable_ca=['stats'])
cv = CrossValidation(clf, splt, enable_ca=['stats'])

results = cv(cds)

#########################################################################

text_file = open(cla.onm, "w")
#text_file.write("subj  roi  num_voxel")
text_file.write(str(cv.ca.stats.stats['ACC%']))

text_file.close()

#########################################################################
if __name__ == "__mvpa_roi__":
    mvpa_roi()
